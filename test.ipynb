{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cedc5e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ben/Thesis/ForgeryLocalization/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import re\n",
    "\n",
    "from scripts.train import train\n",
    "from dataloading.metadata_generator import generate_metadata\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# ignore certain warnings\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\", \n",
    "    message=\"The video decoding and encoding capabilities of torchvision are deprecated from version 0.22\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30302848",
   "metadata": {},
   "source": [
    "Goal: Run training for BA-TFD on a small subset of AV-Deepfake1M-PlusPlus to test the setup.\n",
    "\n",
    "Args:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bf1402",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"config\": 'models/batfd/batfd.toml',\n",
    "    \"data_root\": 'data/',\n",
    "    \"batch_size\": 8,\n",
    "    \"num_workers\": 11,\n",
    "    \"gpus\": 1,\n",
    "    \"precision\": 32,\n",
    "    \"num_train\": 100,\n",
    "    \"num_val\": 100,\n",
    "    \"max_epochs\": 1,\n",
    "    \"logger\": \"tensorboard\",\n",
    "    \"resume\": None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7151bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing metadata file data/train_metadata.json has been removed.\n",
      "Metadata for train saved to data/train_metadata.json\n",
      "Existing metadata file data/val_metadata.json has been removed.\n",
      "Metadata for val saved to data/val_metadata.json\n",
      "Existing file list data/testA_files.txt has been removed.\n",
      "File list for testA saved to data/testA_files.txt\n"
     ]
    }
   ],
   "source": [
    "# prepare metadata\n",
    "generate_metadata(args[\"data_root\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c27c653",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized!\n",
      "DataModule initialized!\n",
      "Trainer initialized!\n",
      "Load 2608 data in train.\n",
      "Load 735 data in val.\n",
      "Load 1419 data in testA.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name                   | Type                              | Params | Mode \n",
      "-------------------------------------------------------------------------------------\n",
      "0 | video_encoder          | C3DVideoEncoder                   | 2.3 M  | train\n",
      "1 | audio_encoder          | CNNAudioEncoder                   | 76.4 K | train\n",
      "2 | video_frame_classifier | FrameLogisticRegression           | 257    | train\n",
      "3 | audio_frame_classifier | FrameLogisticRegression           | 257    | train\n",
      "4 | video_boundary_module  | BoundaryModule                    | 1.5 M  | train\n",
      "5 | audio_boundary_module  | BoundaryModule                    | 1.5 M  | train\n",
      "6 | fusion                 | ModalFeatureAttnBoundaryMapFusion | 32.8 K | train\n",
      "7 | frame_loss             | BCEWithLogitsLoss                 | 0      | train\n",
      "8 | contrast_loss          | ContrastLoss                      | 0      | train\n",
      "9 | bm_loss                | MSELoss                           | 0      | train\n",
      "-------------------------------------------------------------------------------------\n",
      "5.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.5 M     Total params\n",
      "21.963    Total estimated model params size (MB)\n",
      "125       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  19%|█▉        | 24/125 [01:25<06:01,  0.28it/s, v_num=13]        "
     ]
    }
   ],
   "source": [
    "train(args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
